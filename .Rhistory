# Display the count of outliers
cat("Number of outliers:", length(outliers), "\n")
# Identify rows with outliers
outlier_rows <- which(data$YearBuilt %in% outliers)
# Print the indices of rows with outliers
cat("Indices of rows with outliers:", outlier_rows, "\n")
# Remove rows with outliers
data <- data[-outlier_rows, ]
# Print a message after removing outliers
cat("Outliers removed. New number of rows:", nrow(data), "\n")
# Basic descriptive statistics
# Remember that package 'summarytools' is required
freq(ExterQual)
# Pie chart and bar graph
p1<-ggplot(data, aes(x=factor(1), fill = ExterQual))+geom_bar()+
coord_polar("y")+labs(x="ExterQual",y="%")
p2<-ggplot(data, aes(x=factor(1), fill = ExterQual))+geom_bar()+
labs(x="ExterQual",y="%")
# This function controls the graphical output device
# Remember that package 'ggpubr' is required
ggarrange(p1,p2,nrow = 1,ncol=2, common.legend = TRUE)
# Basic descriptive statistics
# Remember that package 'summarytools' is required
freq(ExterCond)
# Pie chart and bar graph
p1<-ggplot(data, aes(x=factor(1), fill = ExterCond))+geom_bar()+
coord_polar("y")+labs(x="ExterCond",y="%")
p2<-ggplot(data, aes(x=factor(1), fill = ExterCond))+geom_bar()+
labs(x="ExterCond",y="%")
# This function controls the graphical output device
# Remember that package 'ggpubr' is required
ggarrange(p1,p2,nrow = 1,ncol=2, common.legend = TRUE)
# Basic descriptive statistics
# Remember that package 'summarytools' is required
freq(GarageQual)
# Pie chart and bar graph
p1<-ggplot(data, aes(x=factor(1), fill = GarageQual))+geom_bar()+
coord_polar("y")+labs(x="GarageQual",y="%")
p2<-ggplot(data, aes(x=factor(1), fill = GarageQual))+geom_bar()+
labs(x="GarageQual",y="%")
# This function controls the graphical output device
# Remember that package 'ggpubr' is required
ggarrange(p1,p2,nrow = 1,ncol=2, common.legend = TRUE)
# Classical numeric descriptive analysis
describe(GrLivArea)
# Histogram and density plots
# Remember that package 'ggplot2' is required
p1<-ggplot(data,aes(x=GrLivArea))+geom_density()+
labs(title = "Density of GrLivArea",x="GrLivArea",y="Values")
p2<-ggplot(data,aes(x=YearBuilt))+geom_histogram()+
labs(title = "Histogram of GrLivArea",x="GrLivArea",y="Values")
# This function controls the graphical output device
# Remember that package 'ggpubr' is required
ggarrange(p1,p2, nrow=1, common.legend = FALSE)
# Missing Values
na_counts <- sum(is.na(data$YearBuilt))
print(na_counts)
print(na_counts/nrow(data))
# Boxplot to visualize outliers
p1 <- ggplot(data, aes(x = GrLivArea)) +
geom_boxplot(outlier.colour = "red", outlier.shape = 1, outlier.size = 2) +
coord_flip() +
labs(title = "Boxplot of GrLivArea", x = "Values", y = "")
ggarrange(p1, nrow=1, common.legend = FALSE)
# Count outliers
outliers <- boxplot.stats(data$GrLivArea)$out
# Display the count of outliers
cat("Number of outliers:", length(outliers), "\n")
# Identify rows with outliers
outlier_rows <- which(data$GrLivArea %in% outliers)
# Print the indices of rows with outliers
cat("Indices of rows with outliers:", outlier_rows, "\n")
# Remove rows with outliers
data <- data[-outlier_rows, ]
# Print a message after removing outliers
cat("Outliers removed. New number of rows:", nrow(data), "\n")
# Histogram representation of the column GrLivArea
par(mfcol = c(1, 1))
# Define the column name
j0 <- "GrLivArea"
# Set the sequence for the x-axis
x0 <- seq(min(data[, j0], na.rm = TRUE), max(data[, j0], na.rm = TRUE), length.out = 50)
# Create a histogram for the entire column
hist(data[, j0], prob = TRUE, col = grey(0.8), main = paste("Histogram of", j0), xlab = j0)
# Overlay normal distribution curve
lines(x0, dnorm(x0, mean(data[, j0], na.rm = TRUE), sd(data[, j0], na.rm = TRUE)), col = "blue", lwd = 2)
# Representation of normal quantiles for the column GrLivArea
par(mfrow = c(1, 1))
# Define the column name
j0 <- "GrLivArea"
# Set the sequence for the x-axis
x0 <- seq(min(data[, j0], na.rm = TRUE), max(data[, j0], na.rm = TRUE), length.out = 50)
# Create a quantile-quantile plot
qqnorm(data[, j0], main = paste("Q-Q Plot of", j0), pch = 19, col = 2)
qqline(data[, j0])
# Assuming 'data' is your original data frame
data_tidy <- melt(data, value.name = "value")
# Use the aggregate function with the correct FUN argument
result <- aggregate(value ~ variable, data = data_tidy,
FUN = function(x) shapiro.test(x)$p.value)
# Print the row corresponding to YearBuilt
print(subset(result, variable == "YearBuilt"))
# Classical numeric descriptive analysis
describe(X1stFlrSF)
# Histogram and density plots
# Remember that package 'ggplot2' is required
p1<-ggplot(data,aes(x=X1stFlrSF))+geom_density()+
labs(title = "Density of 1stFlrSF",x="1stFlrSF",y="Values")
p2<-ggplot(data,aes(x=X1stFlrSF))+geom_histogram()+
labs(title = "Histogram of 1stFlrSF",x="1stFlrSF",y="Values")
# This function controls the graphical output device
# Remember that package 'ggpubr' is required
ggarrange(p1,p2, nrow=1, common.legend = FALSE)
# Missing Values
na_counts <- sum(is.na(data$X1stFlrSF))
print(na_counts)
print(na_counts/nrow(data))
# Boxplot to visualize outliers
p1 <- ggplot(data, aes(x = X1stFlrSF)) +
geom_boxplot(outlier.colour = "red", outlier.shape = 1, outlier.size = 2) +
coord_flip() +
labs(title = "Boxplot of X1stFlrSF", x = "Values", y = "")
ggarrange(p1, nrow=1, common.legend = FALSE)
# Count outliers
outliers <- boxplot.stats(data$X1stFlrSF)$out
# Display the count of outliers
cat("Number of outliers:", length(outliers), "\n")
# Identify rows with outliers
outlier_rows <- which(data$X1stFlrSF %in% outliers)
# Print the indices of rows with outliers
cat("Indices of rows with outliers:", outlier_rows, "\n")
# Remove rows with outliers
data <- data[-outlier_rows, ]
# Print a message after removing outliers
cat("Outliers removed. New number of rows:", nrow(data), "\n")
# Histogram representation of the column X1stFlrSF
par(mfcol = c(1, 1))
# Define the column name
j0 <- "X1stFlrSF"
# Set the sequence for the x-axis
x0 <- seq(min(data[, j0], na.rm = TRUE), max(data[, j0], na.rm = TRUE), length.out = 50)
# Create a histogram for the entire column
hist(data[, j0], prob = TRUE, col = grey(0.8), main = paste("Histogram of", j0), xlab = j0)
# Overlay normal distribution curve
lines(x0, dnorm(x0, mean(data[, j0], na.rm = TRUE), sd(data[, j0], na.rm = TRUE)), col = "blue", lwd = 2)
# Representation of normal quantiles for the column X1stFlrSF
par(mfrow = c(1, 1))
# Define the column name
j0 <- "X1stFlrSF"
# Set the sequence for the x-axis
x0 <- seq(min(data[, j0], na.rm = TRUE), max(data[, j0], na.rm = TRUE), length.out = 50)
# Create a quantile-quantile plot
qqnorm(data[, j0], main = paste("Q-Q Plot of", j0), pch = 19, col = 2)
qqline(data[, j0])
# Assuming 'data' is your original data frame
data_tidy <- melt(data, value.name = "value")
# Use the aggregate function with the correct FUN argument
result <- aggregate(value ~ variable, data = data_tidy,
FUN = function(x) shapiro.test(x)$p.value)
# Print the row corresponding to X1stFlrSF
print(subset(result, variable == "X1stFlrSF"))
# Classical numeric descriptive analysis
describe(X2ndFlrSF)
# Histogram and density plots
# Remember that package 'ggplot2' is required
p1<-ggplot(data,aes(x=X2ndFlrSF))+geom_density()+
labs(title = "Density of X2ndFlrSF",x="X2ndFlrSF",y="Values")
p2<-ggplot(data,aes(x=X2ndFlrSF))+geom_histogram()+
labs(title = "Histogram of X2ndFlrSF",x="X2ndFlrSF",y="Values")
# This function controls the graphical output device
# Remember that package 'ggpubr' is required
ggarrange(p1,p2, nrow=1, common.legend = FALSE)
# Missing Values
na_counts <- sum(is.na(data$X2ndFlrSF))
print(na_counts)
print(na_counts/nrow(data))
# Boxplot to visualize outliers
p1 <- ggplot(data, aes(x = X2ndFlrSF)) +
geom_boxplot(outlier.colour = "red", outlier.shape = 1, outlier.size = 2) +
coord_flip() +
labs(title = "Boxplot of X2ndFlrSF", x = "Values", y = "")
ggarrange(p1, nrow=1, common.legend = FALSE)
# Count outliers
outliers <- boxplot.stats(data$X2ndFlrSF)$out
# Display the count of outliers
cat("Number of outliers:", length(outliers), "\n")
# Identify rows with outliers
outlier_rows <- which(data$X2ndFlrSF %in% outliers)
# Print the indices of rows with outliers
cat("Indices of rows with outliers:", outlier_rows, "\n")
# Histogram representation of the column X1stFlrSF
par(mfcol = c(1, 1))
# Define the column name
j0 <- "X2ndFlrSF"
# Set the sequence for the x-axis
x0 <- seq(min(data[, j0], na.rm = TRUE), max(data[, j0], na.rm = TRUE), length.out = 50)
# Create a histogram for the entire column
hist(data[, j0], prob = TRUE, col = grey(0.8), main = paste("Histogram of", j0), xlab = j0)
# Overlay normal distribution curve
lines(x0, dnorm(x0, mean(data[, j0], na.rm = TRUE), sd(data[, j0], na.rm = TRUE)), col = "blue", lwd = 2)
# Representation of normal quantiles for the column X2ndFlrSF
par(mfrow = c(1, 1))
# Define the column name
j0 <- "X2ndFlrSF"
# Set the sequence for the x-axis
x0 <- seq(min(data[, j0], na.rm = TRUE), max(data[, j0], na.rm = TRUE), length.out = 50)
# Create a quantile-quantile plot
qqnorm(data[, j0], main = paste("Q-Q Plot of", j0), pch = 19, col = 2)
qqline(data[, j0])
# Assuming 'data' is your original data frame
data_tidy <- melt(data, value.name = "value")
# Use the aggregate function with the correct FUN argument
result <- aggregate(value ~ variable, data = data_tidy,
FUN = function(x) shapiro.test(x)$p.value)
# Print the row corresponding to X2ndFlrSF
print(subset(result, variable == "X2ndFlrSF"))
# Classical numeric descriptive analysis
describe(YrSold)
# Histogram and density plots
# Remember that package 'ggplot2' is required
p1<-ggplot(data,aes(x=YrSold))+geom_density()+
labs(title = "Density of YrSold",x="YrSold",y="Values")
p2<-ggplot(data,aes(x=YrSold))+geom_histogram()+
labs(title = "Histogram of YrSold",x="YrSold",y="Values")
# This function controls the graphical output device
# Remember that package 'ggpubr' is required
ggarrange(p1,p2, nrow=1, common.legend = FALSE)
# Missing Values
na_counts <- sum(is.na(data$YrSold))
print(na_counts)
print(na_counts/nrow(data))
# Boxplot to visualize outliers
p1 <- ggplot(data, aes(x = YrSold)) +
geom_boxplot(outlier.colour = "red", outlier.shape = 1, outlier.size = 2) +
coord_flip() +
labs(title = "Boxplot of YrSold", x = "Values", y = "")
ggarrange(p1, nrow=1, common.legend = FALSE)
# Count outliers
outliers <- boxplot.stats(data$YrSold)$out
# Display the count of outliers
cat("Number of outliers:", length(outliers), "\n")
# Identify rows with outliers
outlier_rows <- which(data$YrSold %in% outliers)
# Print the indices of rows with outliers
cat("Indices of rows with outliers:", outlier_rows, "\n")
# Basic descriptive statistics
# Remember that package 'summarytools' is required
freq(SaleType)
# Pie chart and bar graph
p1<-ggplot(data, aes(x=factor(1), fill = SaleType))+geom_bar()+
coord_polar("y")+labs(x="SaleType",y="%")
p2<-ggplot(data, aes(x=factor(1), fill = SaleType))+geom_bar()+
labs(x="SaleType",y="%")
# This function controls the graphical output device
# Remember that package 'ggpubr' is required
ggarrange(p1,p2,nrow = 1,ncol=2, common.legend = TRUE)
# Basic descriptive statistics
# Remember that package 'summarytools' is required
freq(SaleCondition)
# Pie chart and bar graph
p1<-ggplot(data, aes(x=factor(1), fill = SaleCondition))+geom_bar()+
coord_polar("y")+labs(x="SaleCondition",y="%")
p2<-ggplot(data, aes(x=factor(1), fill = SaleCondition))+geom_bar()+
labs(x="SaleCondition",y="%")
# This function controls the graphical output device
# Remember that package 'ggpubr' is required
ggarrange(p1,p2,nrow = 1,ncol=2, common.legend = TRUE)
# Classical numeric descriptive analysis
describe(SalePrice)
# Histogram and density plots
# Remember that package 'ggplot2' is required
p1<-ggplot(data,aes(x=SalePrice))+geom_density()+
labs(title = "Density of SalePrice",x="SalePrice",y="Values")
p2<-ggplot(data,aes(x=SalePrice))+geom_histogram()+
labs(title = "Histogram of SalePrice",x="SalePrice",y="Values")
# This function controls the graphical output device
# Remember that package 'ggpubr' is required
ggarrange(p1,p2, nrow=1, common.legend = FALSE)
# Classical numeric descriptive analysis
describe(log(SalePrice))
# Histogram and density plots
# Remember that package 'ggplot2' is required
p1<-ggplot(data,aes(x=log(SalePrice)))+geom_density()+
labs(title = "Density of SalePrice",x="SalePrice",y="Values")
p2<-ggplot(data,aes(x=log(SalePrice)))+geom_histogram()+
labs(title = "Histogram of SalePrice",x="SalePrice",y="Values")
# This function controls the graphical output device
# Remember that package 'ggpubr' is required
ggarrange(p1,p2, nrow=1, common.legend = FALSE)
# Dividir SalePrice en dos grupos de igual frecuencia
data$PriceCategory <- ntile(data$SalePrice, 2)
# Asignar nombres a las categorías
data$PriceCategory <- ifelse(data$PriceCategory == 1, "Cheap", "Expensive")
# Resto del código para análisis descriptivo y gráficos
describe(data$SalePrice)
p1 <- ggplot(data, aes(x = SalePrice)) +
geom_density() +
labs(title = "Density of SalePrice", x = "SalePrice", y = "Density")
p2 <- ggplot(data, aes(x = SalePrice)) +
geom_histogram(bins = 30) +
labs(title = "Histogram of SalePrice", x = "SalePrice", y = "Count")
ggarrange(p1, p2, nrow = 1, common.legend = FALSE)
# Verificar la nueva variable
table(data$PriceCategory)
# Drop the SalePrice variable
data <- select(data, -SalePrice)
# To verify that the column has been removed, you can view the structure of the dataframe
str(data)
# Basic descriptive statistics
# Remember that package 'summarytools' is required
freq(data$PriceCategory)
# Pie chart and bar graph
p1<-ggplot(data, aes(x=factor(1), fill = PriceCategory))+geom_bar()+
coord_polar("y")+labs(x="SaleType",y="%")
p2<-ggplot(data, aes(x=factor(1), fill = PriceCategory))+geom_bar()+
labs(x="PriceCategory",y="%")
# This function controls the graphical output device
# Remember that package 'ggpubr' is required
ggarrange(p1,p2,nrow = 1,ncol=2, common.legend = TRUE)
###############################
# Correlation at sample level #
###############################
# Select only numeric columns
numeric_data <- data[sapply(data, is.numeric)]
# Are the variables correlated at sample level?
correlation_matrix <- cor(numeric_data)
# Display the first 6x6 portion of the correlation matrix
correlation_matrix
# Compute the determinant of the correlation matrix (for full matrix)
det(correlation_matrix)
###################################
# Correlation at population level #
###################################
# Bartlett's sphericity test:
# This test checks whether the correlations are significantly different from 0
# The null hypothesis is H_0; det(R)=1 means the variables are uncorrelated
# R denotes the correlation matrix
# cortest.bartlett function in the package pysch performs this test
# This function works with standardized data.
# Standardization
numeric_data_scale<-scale(numeric_data)
# Bartlett's sphericity test
cortest.bartlett(cor(numeric_data_scale))
# Polychoric correlation matrix
# Remember that package 'polycor' is required for 'hetcor' function
poly_cor<-hetcor(numeric_data)$correlations
# Remember that package 'ggcorrplot' is required for 'ggcorrplot' function
ggcorrplot(poly_cor, type="lower",hc.order=T)
# Another interesting visual representation is the following
# Remember that package 'corrplot' is required for 'corrplot' function
corrplot(cor(numeric_data), order = "hclust", tl.col='black', tl.cex=1)
# The 'prcomp' function in the base R package performs this analysis
# Parameters 'scale' and 'center' are set to TRUE to consider standardized data
PCA<-prcomp(numeric_data, scale=T, center = T)
# The field 'rotation' of the 'PCA' object is a matrix
# Its columns are the coefficients of the principal components
# Indicates the weight of each variable in the corresponding principal component
PCA$rotation
# Standard deviations of each principal component
PCA$sdev
# The function 'summary' applied to the 'PCA' object provides relevant information
# - Standard deviations of each principal component
# - Proportion of variance explained and cummulative variance
summary(PCA)
# The following graph shows the proportion of explained variance
Explained_variance <- PCA$sdev^2 / sum(PCA$sdev^2)
p1<-ggplot(data = data.frame(Explained_variance, pc = 1:10),
aes(x = pc, y = Explained_variance, fill=Explained_variance )) +
geom_col(width = 0.3) + scale_y_continuous(limits = c(0,0.6)) + theme_bw() +
labs(x = "Principal component", y= "Proportion of variance")
# The following graph shows the proportion of cumulative explained variance
Cummulative_variance<-cumsum(Explained_variance)
p2<-ggplot( data = data.frame(Cummulative_variance, pc = 1:10),
aes(x = pc, y = Cummulative_variance ,fill=Cummulative_variance )) +
geom_col(width = 0.5) +  scale_y_continuous(limits = c(0,1)) + theme_bw() +
labs(x = "Principal component",
y = "Proportion of cumulative variance")
p1
p2
fviz_eig(PCA)
#######################
# Rule of Abdi et al. #
#######################
# Variances
PCA$sdev^2
# Average of variances
mean(PCA$sdev^2)
# These graphical outputs show the projection of the variables in two dimensions
# Display the weight of the variable in the direction of the principal component
# Projection of variables on the first and second principal components
p1 <- fviz_pca_var(PCA, axes = c(1, 2), repel = TRUE, col.var = "cos2",
legend.title = "Distance", title = "Variables (PC1 vs PC2)") + theme_bw()
# Projection on the first and third principal components
p2 <- fviz_pca_var(PCA, axes = c(1, 3), repel = TRUE, col.var = "cos2",
legend.title = "Distance", title = "Variables (PC1 vs PC3)") + theme_bw()
# Projection on the first and fourth principal components
p3 <- fviz_pca_var(PCA, axes = c(1, 4), repel = TRUE, col.var = "cos2",
legend.title = "Distance", title = "Variables (PC1 vs PC4)") + theme_bw()
# Projection on the second and third principal components
p4 <- fviz_pca_var(PCA, axes = c(2, 3), repel = TRUE, col.var = "cos2",
legend.title = "Distance", title = "Variables (PC2 vs PC3)") + theme_bw()
# Projection on the second and fourth principal components
p5 <- fviz_pca_var(PCA, axes = c(2, 4), repel = TRUE, col.var = "cos2",
legend.title = "Distance", title = "Variables (PC2 vs PC4)") + theme_bw()
# Projection on the third and fourth principal components
p6 <- fviz_pca_var(PCA, axes = c(3, 4), repel = TRUE, col.var = "cos2",
legend.title = "Distance", title = "Variables (PC3 vs PC4)") + theme_bw()
# Displaying graphics
p1
p2
p3
p4
p5
p6
# It is also possible to represent the observations
# As well as identify with colors those observations that explain the greatest
# variance of the principal components
p1<-fviz_pca_ind(PCA,axes = c(1,2),col.ind = "contrib",
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
repel=TRUE,legend.title="Contrib.var", title="Records")+theme_bw()
p2<-fviz_pca_ind(PCA,axes=c(1,3),col.ind = "contrib",
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
repel=TRUE,legend.title="Contrib.var", title="Records")+theme_bw()
p3<-fviz_pca_ind(PCA,axes=c(1,4),col.ind = "contrib",
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
repel=TRUE,legend.title="Contrib.var", title="Records")+theme_bw()
p4<-fviz_pca_ind(PCA,axes=c(2,3),col.ind = "contrib",
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
repel=TRUE,legend.title="Contrib.var", title="Records")+theme_bw()
p5<-fviz_pca_ind(PCA,axes=c(2,4),col.ind = "contrib",
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
repel=TRUE,legend.title="Contrib.var", title="Records")+theme_bw()
p6<-fviz_pca_ind(PCA,axes=c(3,4),col.ind = "contrib",
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
repel=TRUE,legend.title="Contrib.var", title="Records")+theme_bw()
# Displaying graphics
p1
p2
p3
p4
p5
p6
# Joint representation of variables and observations
# Relates the possible relationships between the contributions of the records
# to the variances of the components and the weight of the variables in each
# principal component
p1<-fviz_pca(PCA,axes=c(1,2),alpha.ind ="contrib", col.var = "cos2",
col.ind="seagreen",
gradient.cols = c("#FDF50E", "#FD960E", "#FD1E0E"),
repel=TRUE, legend.title="Distancia")+theme_bw()
p2<-fviz_pca(PCA,axes=c(1,3),alpha.ind ="contrib",
col.var = "cos2",col.ind="seagreen",
gradient.cols = c("#FDF50E", "#FD960E", "#FD1E0E"),
repel=TRUE, legend.title="Distancia")+theme_bw()
p3<-fviz_pca(PCA,axes=c(1,4),alpha.ind ="contrib",
col.var = "cos2",col.ind="seagreen",
gradient.cols = c("#FDF50E", "#FD960E", "#FD1E0E"),
repel=TRUE, legend.title="Distancia")+theme_bw()
p4<-fviz_pca(PCA,axes=c(2,3),alpha.ind ="contrib",
col.var = "cos2",col.ind="seagreen",
gradient.cols = c("#FDF50E", "#FD960E", "#FD1E0E"),
repel=TRUE, legend.title="Distancia")+theme_bw()
p5<-fviz_pca(PCA,axes=c(2,4),alpha.ind ="contrib",
col.var = "cos2",col.ind="seagreen",
gradient.cols = c("#FDF50E", "#FD960E", "#FD1E0E"),
repel=TRUE, legend.title="Distancia")+theme_bw()
p6<-fviz_pca(PCA,axes=c(3,4),alpha.ind ="contrib",
col.var = "cos2",col.ind="seagreen",
gradient.cols = c("#FDF50E", "#FD960E", "#FD1E0E"),
repel=TRUE, legend.title="Distancia")+theme_bw()
# Displaying graphics
p1
p2
p3
p4
p5
p6
head(PCA$x)
# Scree plot
scree(poly_cor)
#Parallel analysis
fa.parallel(poly_cor,n.obs=100,fa="fa",fm="ml")
modelo_varimax<-fa(poly_cor,nfactors = 3,rotate = "varimax",
fa="mle")
# The rotated factorial matrix is shown
print(modelo_varimax$loadings,cut=0)
fa.diagram(modelo_varimax)
# Remember that package 'stats' is required for 'factanal' function
# This function only performs the mle method
FA<-factanal(numeric_data,factors=3, rotation="varimax")
FA$loadings
# Royston multivariate normality test
royston_test <- mvn(data = numeric_data, mvnTest = "royston", multivariatePlot = "qq")
royston_test <- mvn(data = numeric_data, mvnTest = "royston", multivariatePlot = "qq")
royston_test <- mvn(data = numeric_data, modelName="modelo", mvnTest = "royston", multivariatePlot = "qq")
royston_test <- mvn(data = numeric_data, modelName="royston", mvnTest = "royston", multivariatePlot = "qq")
modelo_varimax<-fa(poly_cor,nfactors = 3,rotate = "varimax",
fa="mle")
modelo_varimax<-fa(poly_cor,nfactors = 3,rotate = "varimax",
fa="mle")
royston_test <- mvn(data = numeric_data, modelName="modelo_varimax", mvnTest = "royston", multivariatePlot = "qq")
modelo_varimax<-fa(poly_cor,nfactors = 3,rotate = "varimax",
fa="mle")
royston_test <- mvn(data = numeric_data, modelName=modelo_varimax, mvnTest = "royston", multivariatePlot = "qq")
# The rotated factorial matrix is shown
print(modelo_varimax$loadings,cut=0)
fa.diagram(modelo_varimax)
# Remember that package 'stats' is required for 'factanal' function
# This function only performs the mle method
FA<-factanal(numeric_data,factors=3, rotation="varimax")
# Royston multivariate normality test
royston_test <- mvn(data = numeric_data, mvnTest = "royston", multivariatePlot = "qq")
